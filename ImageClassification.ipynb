{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAg1P6hc8ALBDcmeCqFVnR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya828-ctrl/Temporary_add_to_version_control/blob/master/ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L7IauyCzm8-W",
        "outputId": "2dcbab9f-47a1-436b-b80a-a3b8b2b8848f"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcLbmegUj34k",
        "outputId": "a54883ca-5767-4ebc-dfe1-87a4d2d96163"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unxPvkRzkuIz",
        "outputId": "4208b721-b53b-4451-9946-566bdf55e3e1"
      },
      "source": [
        "cd /content/drive/MyDrive/DeepLearningProjects/ImageClassification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/DeepLearningProjects/ImageClassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrWTt2q0kMMR"
      },
      "source": [
        "\n",
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "from tqdm import tqdm \n",
        "import tarfile\n",
        "\n",
        "dataset_folder_path = 'cifar-10-batches-py'\n",
        "\n",
        "class DownloadProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "if not isdir(dataset_folder_path):\n",
        "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
        "        tar.extractall()\n",
        "        tar.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66_h3ZsBkgz4"
      },
      "source": [
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxthm9_lnIy3"
      },
      "source": [
        "\n",
        "def loadBatch(dataset_folder_path, batch_id):\n",
        "  filename=dataset_folder_path+ \"/data_batch_\"+str(batch_id)\n",
        "  with open(filename, mode='rb') as file:\n",
        "    batch = pkl.load(file, encoding='latin1')\n",
        "        \n",
        "  data = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1) \n",
        "  labels = batch['labels']\n",
        "        \n",
        "  return data, labels"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUSAldpfpIRv"
      },
      "source": [
        "def load_label_names():\n",
        "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR6VVo6RsH6q"
      },
      "source": [
        "**Exploring the dataset:-->**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btcs5MjUqhsk"
      },
      "source": [
        "\n",
        "def display_stats(dataset_folder_path, batch_id, sample_id):\n",
        "    data, labels = loadBatch(dataset_folder_path, batch_id)\n",
        "    \n",
        "    if not (0 <= sample_id < len(data)):\n",
        "        print('{} samples in batch {}.  {} is out of range.'.format(len(data), batch_id, sample_id))\n",
        "        return None\n",
        "\n",
        "    print('\\nStats of batch no.{}:'.format(batch_id))\n",
        "    print('Number of Samples: {}\\n'.format(len(data)))\n",
        "    \n",
        "    label_names = load_label_names()\n",
        "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
        "    for key, value in label_counts.items():\n",
        "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key], value))\n",
        "    \n",
        "    sample_image = data[sample_id]\n",
        "    sample_label = labels[sample_id]\n",
        "    \n",
        "    print('\\nExample of Image {}:'.format(sample_id))\n",
        "    print('Image - Shape: {}'.format(sample_image.shape))\n",
        "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
        "    \n",
        "    plt.imshow(sample_image)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "NZPSIGxKrO3U",
        "outputId": "83a8e071-4b42-4834-d2ba-eff0448b20fb"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "batch_id = 5\n",
        "sample_id = 1\n",
        "display_stats(dataset_folder_path, batch_id, sample_id)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Stats of batch no.5:\n",
            "Number of Samples: 10000\n",
            "\n",
            "Label Counts of [0](airplane) : 1014\n",
            "Label Counts of [1](automobile) : 1014\n",
            "Label Counts of [2](bird) : 952\n",
            "Label Counts of [3](cat) : 1016\n",
            "Label Counts of [4](deer) : 997\n",
            "Label Counts of [5](dog) : 1025\n",
            "Label Counts of [6](frog) : 980\n",
            "Label Counts of [7](horse) : 977\n",
            "Label Counts of [8](ship) : 1003\n",
            "Label Counts of [9](truck) : 1022\n",
            "\n",
            "Example of Image 1:\n",
            "Image - Shape: (32, 32, 3)\n",
            "Label - Label Id: 8 Name: ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 251,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O1h8nJVrU7k"
      },
      "source": [
        "def normalize(x):\n",
        "    min = np.min(x)\n",
        "    max = np.max(x)\n",
        "    x = (x-min) / (max-min)\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnQMgxPMteJ_"
      },
      "source": [
        "\n",
        "def one_hot_encode(labelList):\n",
        "    encoded = np.zeros((len(labelList), 10))\n",
        "    \n",
        "    for idx, val in enumerate(labelList):\n",
        "        encoded[idx][val] = 1\n",
        "    \n",
        "    return encoded"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu07hcqbuNEn"
      },
      "source": [
        "def _preprocess_and_save(normalize, one_hot_encode, data, labels, filename):\n",
        "    data = normalize(data)\n",
        "    labels = one_hot_encode(labels)\n",
        "\n",
        "    pkl.dump((data, labels), open(filename, 'wb'))\n",
        "\n",
        "\n",
        "def preprocess_and_save_data(dataset_folder_path, normalize, one_hot_encode):\n",
        "    n_batches = 5\n",
        "    valid_data = []\n",
        "    valid_labels = []\n",
        "\n",
        "    for batch_i in range(1, n_batches + 1):\n",
        "        data, labels = loadBatch(dataset_folder_path, batch_i)\n",
        "        \n",
        "        validationIndex = int(len(data) * 0.1)  #10% validation set\n",
        "\n",
        "        _preprocess_and_save(normalize, one_hot_encode,\n",
        "                             data[:-validationIndex], labels[:-validationIndex], \n",
        "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
        "\n",
        "        valid_data.extend(data[-validationIndex:])\n",
        "        valid_labels.extend(labels[-validationIndex:])\n",
        "\n",
        "    _preprocess_and_save(normalize, one_hot_encode,\n",
        "                         np.array(valid_data), np.array(valid_labels),\n",
        "                         'preprocess_validation.p')\n",
        "\n",
        "    with open(dataset_folder_path + '/test_batch', mode='rb') as file:\n",
        "        batch = pkl.load(file, encoding='latin1')\n",
        "\n",
        "    test_data = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    test_labels = batch['labels']\n",
        "    \n",
        "    _preprocess_and_save(normalize, one_hot_encode,\n",
        "                         np.array(test_data), np.array(test_labels),\n",
        "                         'preprocess_training.p')\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PluXcxQxxGcb"
      },
      "source": [
        "\n",
        "preprocess_and_save_data(dataset_folder_path, normalize, one_hot_encode)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJXeObgZxW7P"
      },
      "source": [
        "import pickle\n",
        "\n",
        "valid_data, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IFc3BiXyoXu"
      },
      "source": [
        "Preprocessing complete:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGvMaq6I8avg",
        "outputId": "9e537a04-2c30-4c26-f7a9-8ac6014feb92"
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHneqO8MzBmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f868369-8adc-4ea3-88f1-05161a523a2a"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKgeTO5Y2ha7"
      },
      "source": [
        "#tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-9k5Pygx1Pp"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
        "y =  tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
        "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ipAE1o4LHN"
      },
      "source": [
        "#pip install tf-slim"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN2fZUEU4R1t"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3plvZ1Noy4TZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_net(x, keep_prob):\n",
        "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
        "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
        "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
        "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
        "\n",
        "    # 1, 2\n",
        "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv1 = tf.nn.relu(conv1)\n",
        "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
        "\n",
        "    # 3, 4\n",
        "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv2 = tf.nn.relu(conv2)\n",
        "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
        "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
        "  \n",
        "    # 5, 6\n",
        "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv3 = tf.nn.relu(conv3)\n",
        "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
        "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
        "    \n",
        "    # 7, 8\n",
        "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv4 = tf.nn.relu(conv4)\n",
        "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
        "    \n",
        "    # 9\n",
        "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
        "\n",
        "    # 10\n",
        "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
        "    full1 = tf.nn.dropout(full1, keep_prob)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    # 11\n",
        "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
        "    full2 = tf.nn.dropout(full2, keep_prob)\n",
        "    full2 = tf.layers.batch_normalization(full2)\n",
        "    \n",
        "    # 12\n",
        "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
        "    full3 = tf.nn.dropout(full3, keep_prob)\n",
        "    full3 = tf.layers.batch_normalization(full3)    \n",
        "    \n",
        "    # 13\n",
        "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
        "    full4 = tf.nn.dropout(full4, keep_prob)\n",
        "    full4 = tf.layers.batch_normalization(full4)        \n",
        "    \n",
        "    # 14\n",
        "    out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
        "    return out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z21NFu01232"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 128\n",
        "keep_probability = 0.7\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "tU1LFwTDF0HO",
        "outputId": "e911ae47-22f7-4d4c-9ff8-b81b40726880"
      },
      "source": [
        "pip install --user gast==0.2.2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=d5e41db2b98f9836adbb46f58b65b365e7f199e92633e471b9b4e78106d77868\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast\n",
            "Successfully installed gast-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XexJiGUP2JtR",
        "outputId": "007ae537-71d4-4095-e289-93829da2d772"
      },
      "source": [
        "\n",
        "logits = conv_net(x, keep_prob)\n",
        "model = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
        "\n",
        "# Loss and Optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# Accuracy\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-a1c31b22992a>:13: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe34fbf34d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe34fbf34d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe34fbf34d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe34fbf34d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe3327ae7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe326ffeed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe326ffeed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe326ffeed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe326ffeed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3326e7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3326e7b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3326e7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3326e7b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From <ipython-input-20-a1c31b22992a>:38: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe328986650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe328986650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe328986650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe328986650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe331d494d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3270d3d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3270d3d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3270d3d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe3270d3d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe328c2c290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe328c2c290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe328c2c290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe328c2c290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32707c2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32707c2d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32707c2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32707c2d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe327b84350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe327b84350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe327b84350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe327b84350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32706d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32706d210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32706d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe32706d210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From <ipython-input-23-6da37c2c1508>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErpEp8_H2Px2"
      },
      "source": [
        "def train_neural_network(session, optimizer, keep_probability, data_batch, label_batch):\n",
        "    session.run(optimizer, \n",
        "                feed_dict={\n",
        "                    x: data_batch,\n",
        "                    y: label_batch,\n",
        "                    keep_prob: keep_probability\n",
        "                })"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiNya-B05Ebc"
      },
      "source": [
        "def print_stats(session, data_batch, label_batch, cost, accuracy):\n",
        "    loss = sess.run(cost, \n",
        "                    feed_dict={\n",
        "                        x: data_batch,\n",
        "                        y: label_batch,\n",
        "                        keep_prob: 1.\n",
        "                    })\n",
        "    valid_acc = sess.run(accuracy, \n",
        "                         feed_dict={\n",
        "                             x: valid_data,\n",
        "                             y: valid_labels,\n",
        "                             keep_prob: 1.\n",
        "                         })\n",
        "    \n",
        "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwyb_zpe5Pfv"
      },
      "source": [
        "def batch_data_labels(data, labels, batch_size):\n",
        "\n",
        "    for start in range(0, len(data), batch_size):\n",
        "        end = min(start + batch_size, len(data))\n",
        "        yield data[start:end], labels[start:end]\n",
        "\n",
        "def load_preprocess_training_batch(batch_id, batch_size):\n",
        "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
        "    data, labels = pkl.load(open(filename, mode='rb'))\n",
        "\n",
        "    # Return the training data in batches of size <batch_size> or less\n",
        "    return batch_data_labels(data, labels, batch_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO51mFCm5qBG",
        "outputId": "925e66cc-3720-4540-d352-abb2eab79193"
      },
      "source": [
        "save_model_path = './image_classification'\n",
        "\n",
        "print('Training...')\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    # Initializing the variables\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    \n",
        "    # Training cycle\n",
        "    for epoch in range(epochs):\n",
        "        # Loop over all batches\n",
        "        n_batches = 5\n",
        "        for batch_i in range(1, n_batches + 1):\n",
        "            for batch_data, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
        "                train_neural_network(sess, optimizer, keep_probability, batch_data, batch_labels)\n",
        "                \n",
        "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
        "            print_stats(sess, batch_data, batch_labels, cost, accuracy)\n",
        "            \n",
        "    # Save Model\n",
        "    saver = tf.train.Saver()\n",
        "    save_path = saver.save(sess, save_model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1574 Validation Accuracy: 0.257600\n",
            "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.8516 Validation Accuracy: 0.266200\n",
            "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.6273 Validation Accuracy: 0.305200\n",
            "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.6868 Validation Accuracy: 0.365400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoRCCrYM562K"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def batch_features_labels(data, labels, batch_size):\n",
        "\n",
        "    for start in range(0, len(data), batch_size):\n",
        "        end = min(start + batch_size, len(data))\n",
        "        yield data[start:end], labels[start:end]\n",
        "\n",
        "def display_image_predictions(data, labels, predictions, top_n_predictions):\n",
        "    n_classes = 10\n",
        "    label_names = load_label_names()\n",
        "    label_binarizer = LabelBinarizer()\n",
        "    label_binarizer.fit(range(n_classes))\n",
        "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
        "\n",
        "    fig, axies = plt.subplots(nrows=top_n_predictions, ncols=2, figsize=(20, 10))\n",
        "    fig.tight_layout()\n",
        "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
        "\n",
        "    n_predictions = 3\n",
        "    margin = 0.05\n",
        "    ind = np.arange(n_predictions)\n",
        "    width = (1. - 2. * margin) / n_predictions\n",
        "   \n",
        "    for image_i, (dat, label_id, pred_indicies, pred_values) in enumerate(zip(data, label_ids, predictions.indices, predictions.values)):\n",
        "        if (image_i < top_n_predictions):\n",
        "            pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
        "            correct_name = label_names[label_id]\n",
        "            \n",
        "            axies[image_i][0].imshow((dat*255).astype(np.int32, copy=False))\n",
        "            axies[image_i][0].set_title(correct_name)\n",
        "            axies[image_i][0].set_axis_off()\n",
        "\n",
        "            axies[image_i][1].barh(ind + margin, pred_values[:3], width)\n",
        "            axies[image_i][1].set_yticks(ind + margin)\n",
        "            axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
        "            axies[image_i][1].set_xticks([0, 0.5, 1.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwvD5iucC8sS"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "save_model_path = './image_classification'\n",
        "batch_size = 64\n",
        "n_samples = 10\n",
        "top_n_predictions = 5\n",
        "\n",
        "def test_model():\n",
        "    test_data, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
        "    loaded_graph = tf.Graph()\n",
        "\n",
        "    with tf.Session(graph=loaded_graph) as sess:\n",
        "        # Load model\n",
        "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
        "        loader.restore(sess, save_model_path)\n",
        "\n",
        "        # Get Tensors from loaded model\n",
        "        loaded_x = loaded_graph.get_tensor_by_name('input_x:0')\n",
        "        loaded_y = loaded_graph.get_tensor_by_name('output_y:0')\n",
        "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
        "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
        "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
        "        \n",
        "        # Get accuracy in batches for memory limitations\n",
        "        test_batch_acc_total = 0\n",
        "        test_batch_count = 0\n",
        "        \n",
        "        for train_dat_batch, train_label_batch in batch_features_labels(test_data, test_labels, batch_size):\n",
        "            test_batch_acc_total += sess.run(\n",
        "                loaded_acc,\n",
        "                feed_dict={loaded_x: train_dat_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
        "            test_batch_count += 1\n",
        "\n",
        "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
        "\n",
        "        # Print Random Samples\n",
        "        random_test_data, random_test_labels = tuple(zip(*random.sample(list(zip(test_data, test_labels)), n_samples)))\n",
        "        random_test_predictions = sess.run(\n",
        "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
        "            feed_dict={loaded_x: random_test_data, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
        "        display_image_predictions(random_test_data, random_test_labels, random_test_predictions, top_n_predictions)\n",
        "\n",
        "\n",
        "test_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}